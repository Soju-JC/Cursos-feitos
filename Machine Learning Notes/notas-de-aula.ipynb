{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas de estudos de Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O processo de ML\n",
    "\n",
    " - **Data Pre-Processing** (Pré-Processamento de dados):\n",
    "    - Importação dos dados.\n",
    "    - Limpeza e exploratória dos dados.\n",
    "    - Separação dos dados em treino e teste.\n",
    " - **Modelling** (Modelagem):\n",
    "    - Construção do modelo.\n",
    "    - Treino do modelo.\n",
    "    - Obter predições.\n",
    " - **Evaluation** (Avaliação ou diagnóstico):\n",
    "    - Cálculo de métricas de performance.\n",
    "    - Decisão: O modelo é bom? Pode ser melhorado? devo descartá-lo? é parcimonioso?."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuring Scaling\n",
    " \n",
    "É o método de mudar a escala dos dados, onde, ao padronizar a escala para todas as colunas, todas deverão contribuir igualmente ao modelo impedindo que colunas com valores em uma escala extrema dominem o modelo, sendo assim, uma boa prática na construção de modelos de ML. Além disso, pode reduzir o efeito de outliers. \n",
    "\n",
    " - **Normalization (Normalização)**: É um método de Featuring Scaling em que consiste em levar os dados para o intervalo [0, 1], onde, isso é feito ao subtrair de cada dado o mínimo da amostra e, posteriormente, dividir pela amplitude (max - min). \n",
    "\n",
    " - **Standardization (Padronização)**: É um método de Featuring Scaling em que consiste em levar os dados para o intervalo [-3, 3], onde, isso é feito ao subtrair de cada dado a média e, posteriormente, dividir pela variância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " - Supervised Learning: O aprendizado supervisionado pode ser pensado em problemas que se encaixam em uma estrutura de regressão, onde teremos dados em variáveis independentes (inputs) e dependentes (resposta, target, rótulo). O algoritmo irá aprender com essas variáveis e então será capaz de prever ou classificar dados dessa natureza. Assim, alguns exemplos de algoritmos são: regressão linear, regressão logística, árvore de decisão, floresta aleatória, XGBoosting, Gradient Boosting, etc. \n",
    " - Unsupervised Learning: O aprendizado não supervisionado, em paralelo ao supervisionado, pode ser pensado em problemas que se encaixam em uma estrutura de regressão, porém, agora, sem uma variável dependente ou rótulo (é como se no aprendizado supervisionado o algoritmo possuísse \"visão\", e o não supervisionado fosse \"cego\"). Dessa forma, o algoritmo irá aprender com as variáveis de entrada disponíveis com o intuito de identificar padrões e estruturas escondidas nos dados. Assim, problemas desse tipo geralmente se enquadram em agrupamento (clusterização) e redução de dimensionalidade (dimensionality reduction).\n",
    " - Reinforced Learning:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
